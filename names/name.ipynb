{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aea673b-2a7c-4e23-b75e-65cc10d55236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Step 1: Setup & Imports\n",
    "\n",
    "import os\n",
    "import random\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98527926-32cd-4905-be34-5cdabb1d9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 2195 first names and 1038 last names.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Correct absolute paths\n",
    "base_path = r\"C:\\Users\\sushm\\OneDrive\\Desktop\\llm_engineering-main\\DBMS-25\\names\"\n",
    "first_path = os.path.join(base_path, \"first_name.txt\")\n",
    "last_path = os.path.join(base_path, \"last_name.txt\")\n",
    "\n",
    "# Verify and load\n",
    "if not os.path.exists(first_path) or not os.path.exists(last_path):\n",
    "    print(\"‚ö†Ô∏è File not found. Check directory contents:\")\n",
    "    print(os.listdir(base_path))\n",
    "else:\n",
    "    with open(first_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        first_names_raw = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    with open(last_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        last_names_raw = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(first_names_raw)} first names and {len(last_names_raw)} last names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec92451c-b954-43ed-8e27-b52b0da3dd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 2195 first names and 1038 last names.\n"
     ]
    }
   ],
   "source": [
    "# ### Step 2: Read Raw Name Files\n",
    "\n",
    "# Use the path variables directly (no quotes)\n",
    "with open(first_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    first_names_raw = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "with open(last_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    last_names_raw = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(first_names_raw)} first names and {len(last_names_raw)} last names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1b331d9-7b6a-4e42-b6f8-428332ddee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Processing chunk 1/4 ...\n",
      "üß† Processing chunk 2/4 ...\n",
      "üß† Processing chunk 3/4 ...\n",
      "üß† Processing chunk 4/4 ...\n",
      "‚úÖ Extracted 427 unique first names.\n",
      "‚úÖ Final list of first names (sample): ['\"Sushil\"', '\"Benoy\"', '\"Ridhi\"', '\"Ratnesh\"', '\"Rabin\"', '\"Paramjit\"', '\"Niraj\"', '\"Nawaz\"', '\"Gurdayal\"', '\"Yakub\"', 'Here is the list of most common and natural-sounding names from the given list, focusing on diversity across alphabets:', '\"Sreelakshmi\"', '\"Vignesh\"', '\"Thirumal\"', '\"Aman\"']\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os, json, random\n",
    "\n",
    "# Connect to local Ollama\n",
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"OLLAMA_API_BASE_URL\", \"http://localhost:11434/v1\"),\n",
    "    api_key=os.getenv(\"OLLAMA_API_KEY\", \"dummy-key\")\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 1: Randomly sample names from all alphabets for better coverage\n",
    "sampled_first_names = random.sample(first_names_raw, min(800, len(first_names_raw)))\n",
    "\n",
    "# ‚úÖ Step 2: Split into chunks to avoid prompt overflow\n",
    "chunks = [sampled_first_names[i:i+200] for i in range(0, len(sampled_first_names), 200)]\n",
    "\n",
    "common_first_names = set()\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"üß† Processing chunk {i+1}/{len(chunks)} ...\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Below is a list of first names (sample {i+1} of {len(chunks)}):\n",
    "    {chunk}\n",
    "\n",
    "    From these, extract the most common or natural-sounding names.\n",
    "    Focus on diversity across alphabets (A‚ÄìZ).\n",
    "    Return only a JSON array of names, no explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3.2\",  # your Ollama model name\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    # Parse response\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        names = json.loads(content)\n",
    "    except:\n",
    "        names = [n.strip(\" -‚Ä¢,\") for n in content.splitlines() if n.strip()]\n",
    "\n",
    "    common_first_names.update(names)\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(common_first_names)} unique first names.\")\n",
    "\n",
    "# ‚úÖ Step 3: Trim or expand to ensure at least 75\n",
    "common_first_names = list(common_first_names)\n",
    "if len(common_first_names) < 75:\n",
    "    common_first_names += random.sample(first_names_raw, 75 - len(common_first_names))\n",
    "\n",
    "common_first_names = common_first_names[:max(75, len(common_first_names))]\n",
    "print(\"‚úÖ Final list of first names (sample):\", common_first_names[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "191b658d-213c-414b-9d74-881aeaef116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated 400 unique, clean full names.\n",
      "‚úÖ Done! File 'combined_names.txt' created successfully.\n",
      "\n",
      "üßæ Sample names:\n",
      "Chandresh Naqvi\n",
      "Layth Dave\n",
      "Anvi Molla\n",
      "Sudipto D‚ÄôAlia\n",
      "Saurav Bedi\n",
      "Iditri Wagh\n",
      "Kalapu Malik\n",
      "Aditi Taneja\n",
      "Nippu Parihar\n",
      "Ankurjeet Bistagond\n"
     ]
    }
   ],
   "source": [
    "# ### Step 4: Generate ~400 Full Names by Combining Randomly\n",
    "\n",
    "import random\n",
    "\n",
    "num_names = 400\n",
    "full_names = set()  # use set to avoid duplicates\n",
    "\n",
    "while len(full_names) < num_names:\n",
    "    first = random.choice(common_first_names).strip('\"').strip(\"'\").strip()\n",
    "    last = random.choice(last_names_raw).strip('\"').strip(\"'\").strip()\n",
    "    full_names.add(f\"{first} {last}\")\n",
    "\n",
    "full_names = list(full_names)\n",
    "print(f\"‚úÖ Generated {len(full_names)} unique, clean full names.\")\n",
    "\n",
    "# ### Step 5: Save Output to File\n",
    "\n",
    "with open(\"combined_names.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for name in full_names:\n",
    "        f.write(name + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Done! File 'combined_names.txt' created successfully.\")\n",
    "\n",
    "# Show sample output\n",
    "print(\"\\nüßæ Sample names:\")\n",
    "for name in full_names[:10]:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e593fef-26e2-41e4-a28f-f7b846abfbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
