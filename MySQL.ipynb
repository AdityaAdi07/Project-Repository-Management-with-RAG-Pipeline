{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42223861-636d-46f3-9aab-199ecfafcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector, json, random\n",
    "\n",
    "# MySQL setup\n",
    "MYSQL_HOST = \"localhost\"\n",
    "MYSQL_USER = \"root\"\n",
    "MYSQL_PASSWORD = \"naraayana\"\n",
    "DB_NAME = \"project_db25_normalized\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db43ded0-dd60-48fa-b8d8-7a7f50992bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üÜï Database created: project_db25_normalized\n"
     ]
    }
   ],
   "source": [
    "# Connect and recreate DB\n",
    "conn = mysql.connector.connect(host=MYSQL_HOST, user=MYSQL_USER, password=MYSQL_PASSWORD)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"DROP DATABASE IF EXISTS {DB_NAME}\")\n",
    "cursor.execute(f\"CREATE DATABASE {DB_NAME}\")\n",
    "cursor.execute(f\"USE {DB_NAME}\")\n",
    "print(f\"üÜï Database created: {DB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef779963-dd96-4965-aa4f-68454b083313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Normalized tables created\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 1Ô∏è‚É£ CREATE TABLES\n",
    "# =====================\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE projects (\n",
    "    project_id VARCHAR(50) PRIMARY KEY,\n",
    "    title TEXT,\n",
    "    objective TEXT,\n",
    "    field VARCHAR(255),\n",
    "    year VARCHAR(10),\n",
    "    department VARCHAR(50) DEFAULT 'ISE'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE authors (\n",
    "    author_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    name VARCHAR(255)\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE teams (\n",
    "    team_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    project_id VARCHAR(50),\n",
    "    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE project_authors (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    team_id INT,\n",
    "    author_id INT,\n",
    "    FOREIGN KEY (team_id) REFERENCES teams(team_id) ON DELETE CASCADE,\n",
    "    FOREIGN KEY (author_id) REFERENCES authors(author_id) ON DELETE CASCADE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"‚úÖ Normalized tables created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea5c3f9-2ca1-49dd-84a2-b2b2bdbe1821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loaded 404 projects and 375 authors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# 2Ô∏è‚É£ LOAD RAW DATA\n",
    "# =====================\n",
    "json_path = \"projects-embedding-augmented.json\"\n",
    "names_path = \"combined_names.txt\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    projects_raw = json.load(f)\n",
    "\n",
    "with open(names_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    author_names = [line.strip() for line in f if len(line.split()) == 2]\n",
    "\n",
    "print(f\"üì¶ Loaded {len(projects_raw)} projects and {len(author_names)} authors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63246e77-b767-477c-b132-b93f54624974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë®‚Äçüè´ Inserted 375 authors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# 3Ô∏è‚É£ INSERT AUTHORS\n",
    "# =====================\n",
    "cursor.executemany(\"INSERT INTO authors (name) VALUES (%s)\", [(n,) for n in author_names])\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute(\"SELECT author_id FROM authors\")\n",
    "author_ids = [row[0] for row in cursor.fetchall()]\n",
    "print(f\"üë®‚Äçüè´ Inserted {len(author_ids)} authors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b9a776-ece5-4144-afc4-7143ea17c2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inserted projects, teams, and team-author links\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for project in projects_raw:\n",
    "    pid = project.get(\"project_id\")\n",
    "    title = project.get(\"title\")\n",
    "    objective = project.get(\"objective\")\n",
    "    field = project.get(\"domain\")\n",
    "    year = project.get(\"year\")\n",
    "\n",
    "    # Skip \"_syn\" duplicates\n",
    "    if \"_syn\" in pid:\n",
    "        continue\n",
    "\n",
    "    # Convert lists or dicts to JSON string\n",
    "    if isinstance(objective, (list, dict)):\n",
    "        objective = json.dumps(objective)\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT IGNORE INTO projects (project_id, title, objective, field, year)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", (pid, title, objective, field, year))\n",
    "\n",
    "    # Teams\n",
    "    for _ in range(3):\n",
    "        cursor.execute(\"INSERT INTO teams (project_id) VALUES (%s)\", (pid,))\n",
    "        team_id = cursor.lastrowid\n",
    "\n",
    "        selected = random.sample(author_ids, random.randint(2, 3))\n",
    "        for aid in selected:\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO project_authors (team_id, author_id) VALUES (%s, %s)\n",
    "            \"\"\", (team_id, aid))\n",
    "\n",
    "conn.commit()\n",
    "print(\"‚úÖ Inserted projects, teams, and team-author links\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19bb1f7-fa6e-4b7b-802a-1d86052a229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Views created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# 5Ô∏è‚É£ CREATE VIEWS\n",
    "# =====================\n",
    "cursor.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW projects_full AS\n",
    "SELECT p.project_id, p.title, p.objective, p.field, p.year,\n",
    "       GROUP_CONCAT(DISTINCT a.name SEPARATOR ', ') AS authors,\n",
    "       p.department\n",
    "FROM projects p\n",
    "JOIN teams t ON p.project_id = t.project_id\n",
    "JOIN project_authors pa ON t.team_id = pa.team_id\n",
    "JOIN authors a ON pa.author_id = a.author_id\n",
    "GROUP BY p.project_id\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW authors_view AS\n",
    "SELECT a.name AS author, p.project_id, p.title, p.year\n",
    "FROM authors a\n",
    "JOIN project_authors pa ON a.author_id = pa.author_id\n",
    "JOIN teams t ON pa.team_id = t.team_id\n",
    "JOIN projects p ON t.project_id = p.project_id\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW teams_view AS\n",
    "SELECT t.team_id, p.project_id, p.title,\n",
    "       GROUP_CONCAT(a.name SEPARATOR ', ') AS authors\n",
    "FROM teams t\n",
    "JOIN project_authors pa ON t.team_id = pa.team_id\n",
    "JOIN authors a ON pa.author_id = a.author_id\n",
    "JOIN projects p ON t.project_id = p.project_id\n",
    "GROUP BY t.team_id\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"‚úÖ Views created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47a9f41-905e-463e-aafa-bbbd2dd5c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç SAMPLE PROJECTS_FULL:\n",
      "('auto001', 'Instagram Reach Analysis', 'Analyze Instagram reach data to identify factors influencing post visibility using Python libraries.', 'Artificial Intelligence / Data Science', '2023', 'Aaditya Dahlan, Achyut Rout, Akhya Purwar, Arihant Dagade, Arushi Maddeshiya, Ashal Fathima, Ashal Puri, Ashish Tiwari, Aviral Doctor, Azmi Cauhan, Chandranshu Dinu, Charita Kakar, Deeksha Jajoo, Ehtisham Taneja, Elango Prajapati, Gurbaksh Khaliq, Hansh Mehendale, Harbans Barai, Iditri Wagh, Inabat Dhindhwal, Jami Kanchapu, Jasbir Maheshwari, Jasbir Roy, Jyotsana Nagi, Kirandeep Krish, Kishan Nanwani, Konkana Dayal, Layth Dave, Mahit Kanda, Nandini Shaikh, Nav Borah, Navya Thakur, Nimesh Shankdhar, Nivedita Saraswat, Palak Asthana, Paramjit Bhatia, Prasanna Chowdhury, Priya Dohrey, Priya Hayer, Rizwa Shahid, Sangeeta Baiswar, Sanjeeda Lala, Sanskar Navas, Sanskar Sura, Satyarth Krishnan, Shagufta Samdharshni, Shaniya Brahmbhatt, Shikha Chandra, Sudhakar Souza, Tanya Praveenchand, Triveni Prashad, Tvarika Sen, Vilas Garde, Zaid Palan, Ziya Mhaske', 'ISE')\n",
      "('auto002', 'Scraping laptop data from Amazon', 'Scrape laptop data from Amazon to aid in price comparison and market research.', 'Artificial Intelligence / Data Science', '2024', 'Abhijit Anjum, Aditi Taneja, Ajith Lakhmani, Akhya Purwar, Antara Chakma, Anubhuti Kisshan, Ashish Menon, Babu Jamloki, Baghyawati Malik, Bhaskor Athar, Bhaskor Rausa, Chandani Gautam, common_names.sort() Malviya, Danish Barnwal, Debesh Priya, Divyasree Heblikar, Faiyaz Mourya, Faiz Sur, Farhan Nanda, Girilal Khandelwal, Gurdayal Pingle, Gurdayal Varty, Hansh Mehendale, Hemlata Maurya, Hemlata Naidu, Ifra Jamloki, Irfan Nadaf, Jaganath Char, Jeet Tata, Khushboo Rishiraj, Kishan Nanwani, Kshitij Rizwan, Manju Nandakumar, Mirza Gour, Nagulan Dhingra, Nandini Shaikh, Nihal Chaudhari, Nivika Sibal, Paramjit Rasheed, Pranav Murlidhar, Priya Hayer, Priyesh Siraj, Ratnesh Gill, Saharsh Gangwal, Sangeeta Dar, Sekhar Kasaudhan, Swara Kannaujia, Swara Oak, Tanya Praveenchand, Tapsee Kakar, Tapsee Nagar, Thanvi Mukherjee, Thirumal Bhaskar, Vandita Gopal, Vishva Prasath, Watika Kothari, Zara Talwar', 'ISE')\n",
      "('auto003', 'Video Game Sales Prediction', 'Build a machine learning model to predict video game sales based on various game attributes using regression algorithms.', 'Artificial Intelligence / Data Science', '2022', 'Abhijit Anjum, Abhijit Sahni, Achyut Raj, Achyut Rout, Akhya Purwar, Ankurjeet Parmer, Ashal Fathima, Aviral Parikh, Azmi Rawlani, Bhaskor Athar, Deeksha Jajoo, Dhairya Varughese, Dheeraj Kaul, Girilal Khandelwal, Hansh Mehendale, Jeet Tata, Jodha Soman, Jyotsana Panghal, Kavisha Mane, Kishan Nanwani, Manya Verma, Mirza Gour, Nandini Shaikh, Nawaz Sengar, Prajjwal Adhya, Prasanna Chowdhury, Prasanna Quraishi, Pratul Nadaf, Privrata Virk, Priyesh Buch, Ratnesh Gill, Ravisankar Savant, Sahiti Theratipally, Sanjit Motwani, Sarin Awasthi, Sekhar Kasaudhan, Shukant Arya, Shyam Priyadarshi, Siddhesh Venkatesh, Snehit Bauri, Sultan Gera, Surbhi Mukhopadhyay, Surbhi Rao, Swara Barad, Tapsee Kakar, Tapsee Parsa, Triveni Azhar, Triveni Prashad, Vikram Anand, Watika Kothari, Yachana Mallick, Zaid Palan', 'ISE')\n",
      "\n",
      "üîç SAMPLE TEAMS:\n",
      "(1, 'auto001', 'Instagram Reach Analysis', 'Sanjeeda Lala, Tvarika Sen, Tanya Praveenchand')\n",
      "(2, 'auto001', 'Instagram Reach Analysis', 'Nandini Shaikh, Nivedita Saraswat')\n",
      "(3, 'auto001', 'Instagram Reach Analysis', 'Ashal Puri, Hansh Mehendale')\n",
      "\n",
      "‚úÖ Normalized database build complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# 6Ô∏è‚É£ PREVIEW OUTPUT\n",
    "# =====================\n",
    "print(\"\\nüîç SAMPLE PROJECTS_FULL:\")\n",
    "cursor.execute(\"SELECT * FROM projects_full LIMIT 3\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nüîç SAMPLE TEAMS:\")\n",
    "cursor.execute(\"SELECT * FROM teams_view LIMIT 3\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"\\n‚úÖ Normalized database build complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd5b75-9039-4866-b3a6-3d75e3692cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
